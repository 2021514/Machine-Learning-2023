{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [[0.0794059  0.92367493 0.43787835 0.81333271 0.51651823 0.09850467]\n",
      " [0.96708127 0.87338758 0.27649303 0.21545931 0.06085395 0.95977758]\n",
      " [0.59290121 0.18855192 0.49817963 0.4980895  0.04520311 0.46983905]\n",
      " [0.60719807 0.45602215 0.85223572 0.14063419 0.60431076 0.31593875]\n",
      " [0.77940636 0.39593495 0.00462042 0.44176037 0.42108853 0.53754588]\n",
      " [0.9918958  0.34237261 0.92831006 0.41349058 0.6670381  0.76123018]]\n",
      "\n",
      "Kernel:\n",
      " [[-8.69058504e-01 -5.96897237e-02 -8.73251311e-01 -1.38554435e-01\n",
      "  -1.87291373e-04]\n",
      " [-4.79196670e-01 -1.09387936e+00 -5.43690442e-01 -2.34982687e-02\n",
      "   1.02987232e+00]\n",
      " [ 5.36859442e-02  9.24942414e-01 -2.20802921e-01 -4.23817445e-01\n",
      "   9.86260577e-01]\n",
      " [ 5.74697879e-01 -3.11859529e-01  1.29751232e+00  5.17936243e-01\n",
      "   1.20349945e+00]\n",
      " [ 6.80090038e-01 -3.11211484e-01  4.77241430e-01  1.51500034e-01\n",
      "   2.14290344e-01]]\n",
      "\n",
      "Convoluted Output:\n",
      " [[0.47775353 0.87300845]\n",
      " [1.195016   1.5113761 ]]\n",
      "\n",
      "Pooled Output:\n",
      " [[0.47775353 0.87300845]\n",
      " [1.195016   1.5113761 ]]\n",
      "\n",
      "Gradient wrt Input of Convolution Layer:\n",
      " [[-1.18892259 -1.14555677 -0.3373417   0.84565355  0.19630572  0.        ]\n",
      " [ 0.13220805 -0.47641164 -0.50065229  1.30155467  0.35278225  0.        ]\n",
      " [ 0.3485254   1.06957738  0.42416781  1.57775112  0.38721976  0.        ]\n",
      " [-0.20877739  0.98880429  0.70382621  0.93675658  0.23339039  0.        ]\n",
      " [-0.05759732  0.20538442  0.1573543   0.1388145   0.03428254  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]]\n",
      "\n",
      "Gradient wrt Kernel of Convolution Layer:\n",
      " [[0.01270349 0.19022803 0.56392521 0.36424419 0.51750811]\n",
      " [0.16985332 0.90016178 1.37713656 0.70828442 0.91237726]\n",
      " [0.2792185  1.3328916  0.97306804 0.62134424 0.46766707]\n",
      " [0.21017175 0.93580259 0.63486386 0.99513591 0.60241993]\n",
      " [0.24044749 1.081368   0.76120356 0.8218792  0.53790473]]\n",
      "\n",
      "Gradient wrt Input of Pooling Layer:\n",
      " [[0.94187978 0.99107855]\n",
      " [0.8801611  0.36552241]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CNN:\n",
    "    def conv_forward_2d(self, input, kernel, stride=1, padding=0):\n",
    "        H, W = input.shape\n",
    "        F, x = kernel.shape\n",
    "        # Apply padding\n",
    "        padded_input = np.pad(input, ((padding, padding), (padding, padding)), mode='constant')\n",
    "        # print(padded_input)\n",
    "        # Calculate output dimensions\n",
    "        out_height = ((H - F + 2 * padding) // stride) + 1\n",
    "        out_width = ((W - F + 2 * padding) // stride) + 1\n",
    "\n",
    "        # Perform convolution\n",
    "        out = np.zeros((out_height, out_width)) #declaring the 2d numpy array for output.\n",
    "        for h in range(out_height):\n",
    "            for w in range(out_width):\n",
    "                h_start, w_start = h * stride, w * stride\n",
    "                h_end, w_end = h_start + F, w_start + F\n",
    "                out[h, w] = np.sum(padded_input[h_start:h_end, w_start:w_end] * kernel) #Calculating the cell in feature map\n",
    "\n",
    "        return out\n",
    "\n",
    "    def pool_forward_2d(self, input, pool_size, stride):\n",
    "        H, W = input.shape\n",
    "        pool_height, pool_width = pool_size\n",
    "\n",
    "        # Calculate output dimensions using below formulaes\n",
    "        out_height = (H - pool_height) // stride + 1\n",
    "        out_width = (W - pool_width) // stride + 1\n",
    "\n",
    "        # Perform pooling\n",
    "        out = np.zeros((out_height, out_width)) #declaring the 2d numpy array for output.\n",
    "        for h in range(out_height):\n",
    "            for w in range(out_width):\n",
    "                h_start, w_start = h * stride, w * stride\n",
    "                h_end, w_end = h_start + pool_height, w_start + pool_width\n",
    "                out[h, w] = np.max(input[h_start:h_end, w_start:w_end]) #using max pooling.\n",
    "\n",
    "        return out\n",
    "    def conv_backward_2d(self, d_out, input, kernel, stride=1, padding=1):\n",
    "        H, W = input.shape\n",
    "        F, x = kernel.shape\n",
    "\n",
    "        padded_input = np.pad(input, ((padding, padding), (padding, padding)), mode='constant')\n",
    "        d_input = np.zeros_like(input) #gradient w.r.t original input\n",
    "        d_kernel = np.zeros_like(kernel) #gradient w.r.t to kernel\n",
    "\n",
    "        # Add padding \n",
    "        d_padded_input = np.pad(d_input, ((padding, padding), (padding, padding)), mode='constant')\n",
    "        #updating the above defined gradients\n",
    "        for h in range(d_out.shape[0]):\n",
    "            for w in range(d_out.shape[1]):\n",
    "                h_start, w_start = h * stride, w * stride\n",
    "                h_end, w_end = h_start + F, w_start + F\n",
    "                # Gradient with respect to input\n",
    "                d_padded_input[h_start:h_end, w_start:w_end] += kernel * d_out[h, w]\n",
    "                # Gradient with respect to kernel\n",
    "                d_kernel += padded_input[h_start:h_end, w_start:w_end] * d_out[h, w]\n",
    "\n",
    "        # Remove padding from the gradient with respect to input\n",
    "        if padding != 0:\n",
    "            d_input = d_padded_input[padding:-padding, padding:-padding]\n",
    "        else:\n",
    "            d_input = d_padded_input\n",
    "\n",
    "        return d_input, d_kernel\n",
    "\n",
    "    def pool_backward_2d(self, d_out, input, pool_size, stride):\n",
    "        H, W = input.shape\n",
    "        pool_height, pool_width = pool_size\n",
    "\n",
    "        d_input = np.zeros_like(input)# gradient w.r.t original inputs\n",
    "\n",
    "        for h in range(d_out.shape[0]):\n",
    "            for w in range(d_out.shape[1]):\n",
    "                h_start, w_start = h * stride, w * stride\n",
    "                h_end, w_end = h_start + pool_height, w_start + pool_width\n",
    "                patch = input[h_start:h_end, w_start:w_end]\n",
    "                max_value = np.max(patch) #extract max value\n",
    "\n",
    "                # Place the gradient in the correct location\n",
    "                for i in range(pool_height):\n",
    "                    for j in range(pool_width):\n",
    "                        if patch[i, j] == max_value:\n",
    "                            d_input[h_start + i, w_start + j] = d_out[h, w]\n",
    "\n",
    "        return d_input\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "input_data = np.random.rand(6,6)\n",
    "kernel_data = np.random.randn(5,5)\n",
    "# Sample input data and kernel\n",
    "# input_data = np.array([[1, 6, 2], [5, 3, 1], [7, 0, 4]], dtype=float)\n",
    "# kernel_data = np.array([[1, 2], [-1, 0]], dtype=float)\n",
    "\n",
    "# Forward pass\n",
    "convoluted_output = cnn.conv_forward_2d(input_data, kernel_data)\n",
    "pool_size = (1, 1)\n",
    "stride = 1\n",
    "pooled_output = cnn.pool_forward_2d(convoluted_output, pool_size, stride)\n",
    "\n",
    "d_out_conv = np.random.rand(*convoluted_output.shape) #The gradient of the loss with respect to the output of the convolution layer.\n",
    "d_out_pool = np.random.rand(*pooled_output.shape)\n",
    "\n",
    "# Backward pass\n",
    "d_input_conv, d_kernel_conv = cnn.conv_backward_2d(d_out_conv, input_data, kernel_data)\n",
    "d_input_pool = cnn.pool_backward_2d(d_out_pool, convoluted_output, pool_size, stride)\n",
    "print(\"Input:\\n\",input_data)\n",
    "print(\"\\nKernel:\\n\", kernel_data)\n",
    "print(\"\\nConvoluted Output:\\n\", convoluted_output)\n",
    "print(\"\\nPooled Output:\\n\", pooled_output)\n",
    "print(\"\\nGradient wrt Input of Convolution Layer:\\n\", d_input_conv)\n",
    "print(\"\\nGradient wrt Kernel of Convolution Layer:\\n\", d_kernel_conv)\n",
    "print(\"\\nGradient wrt Input of Pooling Layer:\\n\", d_input_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#In three dimension\n",
    "def conv_forward(input, kernel, stride=1, padding=1):\n",
    "    H, W, C = input.shape\n",
    "    F, x, y = kernel.shape\n",
    "\n",
    "    # Apply padding\n",
    "    padded_input = np.pad(input, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "    print(padded_input)\n",
    "    # Calculate output dimensions\n",
    "    out_height = (H - F + 2 * padding) // stride + 1\n",
    "    out_width = (W - F + 2 * padding) // stride + 1\n",
    "\n",
    "    # Perform convolution\n",
    "    out = np.zeros((out_height, out_width, C))\n",
    "    for h in range(out_height):\n",
    "        for w in range(out_width):\n",
    "            h_start, w_start = h * stride, w * stride\n",
    "            h_end, w_end = h_start + F, w_start + F\n",
    "            out[h, w, :] = np.sum(padded_input[h_start:h_end, w_start:w_end, :] * kernel, axis=(0, 1))\n",
    "    \n",
    "    return out\n",
    "\n",
    "input_example = np.random.rand(5, 5, 3)\n",
    "print(input_example)\n",
    "kernel_example = np.random.rand(3, 3, 3)\n",
    "conv_out = conv_forward(input_example, kernel_example)\n",
    "print(\"Convolution Output:\\n\", conv_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def conv_backward(dout, input, kernel, stride=1, padding=1):\n",
    "    H, W, C = input.shape\n",
    "    F, _, _ = kernel.shape\n",
    "    out_height, out_width, _ = dout.shape\n",
    "\n",
    "    # Apply padding\n",
    "    padded_input = np.pad(input, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "    dpadded_input = np.zeros_like(padded_input)\n",
    "    \n",
    "    # Perform convolution backward pass\n",
    "    for h in range(out_height):\n",
    "        for w in range(out_width):\n",
    "            h_start, w_start = h * stride, w * stride\n",
    "            h_end, w_end = h_start + F, w_start + F\n",
    "            dpadded_input[h_start:h_end, w_start:w_end, :] += kernel * dout[h, w, np.newaxis, np.newaxis, :]\n",
    "\n",
    "    # Remove padding\n",
    "    # print(dpadded_input)\n",
    "    dinput = dpadded_input[padding:-padding, padding:-padding, :]\n",
    "    return dinput\n",
    "\n",
    "# Example usage\n",
    "input_example = np.random.rand(5, 5, 3)\n",
    "# print(input_example)\n",
    "kernel_example = np.random.rand(3, 3, 3)\n",
    "dout_example = np.random.rand(3, 3, 3)\n",
    "conv_backward_out = conv_backward(dout_example, input_example, kernel_example)\n",
    "print(\"Convolution Backward Output:\\n\", conv_backward_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def pool_forward(input, pool_size, stride):\n",
    "    H, W, C = input.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "\n",
    "    # Calculate output dimensions\n",
    "    out_height = (H - pool_height) // stride + 1\n",
    "    out_width = (W - pool_width) // stride + 1\n",
    "\n",
    "    # Perform pooling\n",
    "    out = np.zeros((out_height, out_width, C))\n",
    "    for h in range(out_height):\n",
    "        for w in range(out_width):\n",
    "            h_start, w_start = h * stride, w * stride\n",
    "            h_end, w_end = h_start + pool_height, w_start + pool_width\n",
    "            out[h, w, :] = np.max(input[h_start:h_end, w_start:w_end, :], axis=(0, 1))\n",
    "\n",
    "    return out\n",
    "input_example = np.random.rand(5, 5, 3)\n",
    "pool_out = pool_forward(input_example, pool_size=(2, 2), stride=2)\n",
    "print(\"Pooling Output:\\n\", pool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pool_backward(dout, input, pool_size, stride):\n",
    "    H, W, C = input.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "    out_height, out_width, _ = dout.shape\n",
    "    dinput = np.zeros_like(input)\n",
    "\n",
    "    for h in range(out_height):\n",
    "        for w in range(out_width):\n",
    "            h_start, w_start = h * stride, w * stride\n",
    "            h_end, w_end = h_start + pool_height, w_start + pool_width\n",
    "            pool_region = input[h_start:h_end, w_start:w_end, :]\n",
    "            max_pool_indices = pool_region == np.max(pool_region, axis=(0, 1), keepdims=True)\n",
    "            dinput[h_start:h_end, w_start:w_end, :] += max_pool_indices * dout[h, w, np.newaxis, np.newaxis, :]\n",
    "\n",
    "    return dinput\n",
    "\n",
    "dout_example = np.random.rand(3, 3, 3)\n",
    "input_example = np.random.rand(5, 5, 3)\n",
    "pool_backward_out = pool_backward(dout_example, input_example, pool_size=(2, 2), stride=2)\n",
    "print(\"Pooling Backward Output:\\n\", pool_backward_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
